# üìã –§–∞–∑–∞ 2: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ - –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

## üéØ –û–±—â–∞—è —Ü–µ–ª—å –§–∞–∑—ã 2
–î–æ–±–∞–≤–∏—Ç—å –∫ Enhanced MCP —Å–µ—Ä–≤–µ—Ä—É –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ **—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è** –∑–∞–º–µ—Ç–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è:
- –ü–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–º–µ—Ç–æ–∫ –ø–æ —Å–º—ã—Å–ª—É (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ —Å–ª–æ–≤–∞–º)
- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º–∏
- –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

---

## üõ†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### **–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ ML/AI:**
```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
pip install sentence-transformers>=2.2.2  # Embeddings –º–æ–¥–µ–ª–µ–π
pip install numpy>=1.24.0                # –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
pip install scikit-learn>=1.3.0          # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∏ –º–µ—Ç—Ä–∏–∫–∏
pip install spacy>=3.6.0                 # NLP –æ–±—Ä–∞–±–æ—Ç–∫–∞
pip install torch>=2.0.0                 # PyTorch –¥–ª—è –º–æ–¥–µ–ª–µ–π

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
python -m spacy download en_core_web_sm   # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
python -m spacy download ru_core_news_sm  # –†—É—Å—Å–∫–∏–π (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
```

### **–ú–æ–¥–µ–ª–∏ –¥–ª—è embeddings:**
- **sentence-transformers/all-MiniLM-L6-v2** (384 dim, 80MB) - –±—ã—Å—Ç—Ä–∞—è –∏ –ª–µ–≥–∫–∞—è
- **sentence-transformers/all-mpnet-base-v2** (768 dim, 420MB) - –±–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è
- **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2** - –¥–ª—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ—Å—Ç–∏

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è

### **–ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
```
src/obsidian_mcp/
‚îú‚îÄ‚îÄ server.py                    # [—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π] –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–µ—Ä
‚îú‚îÄ‚îÄ smart_search.py              # [—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π] –¢–µ–∫—É—â–∏–π –ø–æ–∏—Å–∫
‚îú‚îÄ‚îÄ ai/                          # [–ù–û–í–´–ô] –ò–ò –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py            # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ embeddings
‚îÇ   ‚îú‚îÄ‚îÄ similarity.py            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–º–µ—Ç–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ contextual_search.py     # –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫  
‚îÇ   ‚îú‚îÄ‚îÄ connections.py           # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π
‚îÇ   ‚îî‚îÄ‚îÄ models.py                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ database/                    # [–ù–û–í–´–ô] –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ë–î
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ schema_v2.sql           # –ù–æ–≤–∞—è —Å—Ö–µ–º–∞ —Å embeddings
‚îÇ   ‚îú‚îÄ‚îÄ migrations.py           # –ú–∏–≥—Ä–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ë–î
‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py         # –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
‚îî‚îÄ‚îÄ utils/                       # [—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ] –£—Ç–∏–ª–∏—Ç—ã
```

---

## üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### **üîß –≠—Ç–∞–ø 2.1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ AI –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (1 –Ω–µ–¥–µ–ª—è)**

#### **–î–µ–Ω—å 1-2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –±–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞**
```bash
# –ó–∞–¥–∞—á–∏:
‚úì –î–æ–±–∞–≤–∏—Ç—å ML –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ pyproject.toml
‚úì –°–æ–∑–¥–∞—Ç—å ai/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥—É–ª—è–º–∏
‚úì –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚úì –°–æ–∑–¥–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è AI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

# –§–∞–π–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è:
- src/obsidian_mcp/ai/models.py
- src/obsidian_mcp/ai/__init__.py  
- ai_config.yaml (–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π)
```

**models.py —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```python
class EmbeddingManager:
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.cache_dir = vault_path / ".obsidian" / "embeddings_cache"
    
    async def get_embedding(self, text: str) -> np.ndarray:
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –ø–æ —Ö–µ—à—É —Ç–µ–∫—Å—Ç–∞
    
    async def batch_embed(self, texts: List[str]) -> np.ndarray:
        # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
```

#### **–î–µ–Ω—å 3-4: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**
```sql
-- –ù–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ schema_v2.sql
CREATE TABLE note_embeddings (
    note_title TEXT PRIMARY KEY,
    embedding BLOB,              -- –°–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π numpy array
    embedding_model TEXT,        -- –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    content_hash TEXT,           -- –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

CREATE TABLE semantic_clusters (
    cluster_id INTEGER PRIMARY KEY,
    cluster_name TEXT,
    representative_notes TEXT,   -- JSON —Å–ø–∏—Å–æ–∫ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–º–µ—Ç–æ–∫
    created_at TIMESTAMP
);

CREATE TABLE note_similarities (
    note1_title TEXT,
    note2_title TEXT, 
    similarity_score REAL,
    model_used TEXT,
    calculated_at TIMESTAMP,
    PRIMARY KEY (note1_title, note2_title)
);
```

#### **–î–µ–Ω—å 5-7: –ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö**
```python
# database/migrations.py
async def migrate_to_v2():
    # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    # –°–æ–∑–¥–∞—Ç—å embeddings –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–º–µ—Ç–æ–∫
    # –û–±–Ω–æ–≤–∏—Ç—å smart_search.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
```

### **üß† –≠—Ç–∞–ø 2.2: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (1-2 –Ω–µ–¥–µ–ª–∏)**

#### **–ù–µ–¥–µ–ª—è 1: find_similar_notes**
```python
@mcp.tool()
def find_similar_notes(
    ctx: Context[ServerSession, AppContext],
    reference_note: str,
    similarity_threshold: float = 0.7,
    limit: int = 10,
    include_scores: bool = True
) -> Dict[str, Any]:
    """
    üîç FIND SIMILAR NOTES - Semantic similarity search
    
    PURPOSE: Find notes with similar meaning, not just similar words.
    Uses AI embeddings to understand semantic relationships.
    
    FEATURES:
    ‚Ä¢ Semantic understanding (finds "neural networks" when searching "deep learning")
    ‚Ä¢ Multilingual similarity (—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö)
    ‚Ä¢ Adjustable similarity threshold
    ‚Ä¢ Scored results with explanation
    
    USE CASES:
    ‚Ä¢ Research: "Find notes similar to my machine learning introduction"
    ‚Ä¢ Knowledge gaps: "What else do I have on this topic?"
    ‚Ä¢ Content connections: "Show related concepts to artificial intelligence"
    """
```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
# ai/similarity.py
class NoteSimilarityAnalyzer:
    def __init__(self, embedding_manager, vector_store):
        self.embeddings = embedding_manager
        self.vector_store = vector_store
    
    async def find_similar(self, reference_note: str, threshold: float, limit: int):
        # 1. –ü–æ–ª—É—á–∏—Ç—å embedding —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –∑–∞–º–µ—Ç–∫–∏
        ref_embedding = await self.embeddings.get_note_embedding(reference_note)
        
        # 2. –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        similar_embeddings = await self.vector_store.similarity_search(
            ref_embedding, threshold, limit
        )
        
        # 3. –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        return self.format_similarity_results(similar_embeddings)
```

#### **–ù–µ–¥–µ–ª—è 2: search_contextual**
```python
@mcp.tool() 
def search_contextual(
    ctx: Context[ServerSession, AppContext],
    query: str,
    context: Optional[str] = None,
    search_intent: str = "general",  # "research", "reference", "brainstorm"
    include_semantic: bool = True,
    limit: int = 15
) -> Dict[str, Any]:
    """
    üéØ CONTEXTUAL SEARCH - AI-powered search with intent understanding
    
    PURPOSE: Smart search that understands what you're trying to accomplish,
    not just matching keywords. Uses context and intent to find relevant notes.
    
    FEATURES:  
    ‚Ä¢ Intent recognition (research vs reference vs brainstorming)
    ‚Ä¢ Contextual understanding ("Python" means programming in tech context)
    ‚Ä¢ Semantic expansion (finds related concepts automatically)
    ‚Ä¢ Query reformulation for better results
    
    USE CASES:
    ‚Ä¢ Research mode: "Find technical details about React performance"
    ‚Ä¢ Reference mode: "Quick lookup of authentication patterns" 
    ‚Ä¢ Brainstorm mode: "Show me creative ideas related to user experience"
    """
```

### **üîó –≠—Ç–∞–ø 2.3: –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π (1 –Ω–µ–¥–µ–ª—è)**

#### **analyze_note_connections**
```python
@mcp.tool()
def analyze_note_connections(
    ctx: Context[ServerSession, AppContext], 
    note_title: str,
    analysis_depth: int = 2,
    connection_threshold: float = 0.6,
    suggest_new_links: bool = True
) -> Dict[str, Any]:
    """
    üï∏Ô∏è ANALYZE NOTE CONNECTIONS - Deep relationship analysis
    
    PURPOSE: Understand how a note fits into your knowledge graph.
    Discovers both explicit links and implicit semantic relationships.
    
    FEATURES:
    ‚Ä¢ Multi-level relationship analysis (direct, indirect, conceptual)
    ‚Ä¢ Gap detection (missing connections that should exist)
    ‚Ä¢ Cluster analysis (what conceptual groups this note belongs to)  
    ‚Ä¢ Link suggestions with confidence scores
    
    RETURNS:
    ‚Ä¢ Existing connections (explicit links)
    ‚Ä¢ Semantic connections (implicit relationships)
    ‚Ä¢ Missing connections (should be linked but aren't)
    ‚Ä¢ Conceptual clusters (thematic groups)
    ‚Ä¢ Actionable suggestions
    """
```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
# ai/connections.py  
class ConnectionAnalyzer:
    async def analyze_connections(self, note_title: str, depth: int):
        # 1. –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–≤—è–∑–µ–π
        explicit_links = await self.get_explicit_links(note_title, depth)
        
        # 2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π
        semantic_connections = await self.find_semantic_connections(note_title)
        
        # 3. –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        clusters = await self.analyze_clusters(note_title)
        
        # 4. –ü–æ–∏—Å–∫ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ —Å–≤—è–∑—è—Ö
        missing_links = await self.suggest_missing_links(note_title)
        
        return {
            "explicit_connections": explicit_links,
            "semantic_connections": semantic_connections, 
            "clusters": clusters,
            "suggested_links": missing_links,
            "analysis_metadata": {...}
        }
```

---

## üóÉÔ∏è –°–∏—Å—Ç–µ–º–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞

### **–í—ã–±–æ—Ä –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î:**
```python
# –í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏):

# 1. –ü–†–û–°–¢–û–ô: –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ SQLite (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—á–∞–ª–∞)
# Pros: –ë–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, –ø—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
# Cons: –ú–µ–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π (>10k –∑–∞–º–µ—Ç–æ–∫)

# 2. –°–†–ï–î–ù–ò–ô: ChromaDB 
# Pros: –õ–µ–≥–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è, —Ö–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
# Cons: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å

# 3. –ü–†–û–î–í–ò–ù–£–¢–´–ô: Pinecone/Weaviate
# Pros: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –æ–±–ª–∞—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
# Cons: –¢—Ä–µ–±—É–µ—Ç –≤–Ω–µ—à–Ω–µ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
```

### **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (SQLite + numpy):**
```python
# database/vector_store.py
class SQLiteVectorStore:
    def __init__(self, db_path: Path):
        self.conn = sqlite3.connect(db_path)
        
    async def store_embedding(self, note_title: str, embedding: np.ndarray):
        # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è embedding –≤ BLOB
        embedding_blob = embedding.tobytes()
        
    async def similarity_search(self, query_embedding: np.ndarray, threshold: float, limit: int):
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö embeddings (–¥–ª—è –º–∞–ª—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π)
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ cosine similarity —Å numpy
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### **–ë–µ–Ω—á–º–∞—Ä–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:**
```python
# –¶–µ–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
- –ü–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ 1000 –∑–∞–º–µ—Ç–æ–∫: < 500ms
- –°–æ–∑–¥–∞–Ω–∏–µ embedding –Ω–æ–≤–æ–π –∑–∞–º–µ—Ç–∫–∏: < 200ms  
- Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ 100 –∑–∞–º–µ—Ç–æ–∫: < 30s
- –†–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞: < 50MB –¥–ª—è 1000 –∑–∞–º–µ—Ç–æ–∫
- RAM –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: < 500MB –ø—Ä–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
```

### **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**
```python
# 1. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –Ω–∞ –¥–∏—Å–∫–µ
# 2. Lazy loading –º–æ–¥–µ–ª–µ–π (–∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)
# 3. Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–º–µ—Ç–æ–∫
# 4. –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
# 5. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ (–æ—Ç –±—ã—Å—Ç—Ä—ã—Ö –¥–æ —Ç–æ—á–Ω—ã—Ö)
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –§–∞–∑—ã 2

### **–¢–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏:**
```python
# test_semantic_phase2.py
async def test_similarity_search():
    # 1. –°–æ–∑–¥–∞—Ç—å –∑–∞–º–µ—Ç–∫–∏ –Ω–∞ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–º—ã
    # 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ find_similar_notes –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
    # 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ similarity scores —Ä–∞–∑—É–º–Ω—ã–µ (0.7+)
    
async def test_multilingual_similarity():
    # 1. –ó–∞–º–µ—Ç–∫–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –ø—Ä–æ "machine learning"
    # 2. –ó–∞–º–µ—Ç–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –ø—Ä–æ "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ" 
    # 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –æ–Ω–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –ø–æ—Ö–æ–∂–∏–º–∏
    
async def test_contextual_search():
    # 1. –ü–æ–∏—Å–∫ "Python" –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ programming
    # 2. –ü–æ–∏—Å–∫ "Python" –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ animals
    # 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
```

---

## ‚ö†Ô∏è –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

### **1. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- **–ü—Ä–æ–±–ª–µ–º–∞**: ML –º–æ–¥–µ–ª–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ CPU
- **–†–µ—à–µ–Ω–∏–µ**: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ, batch –æ–±—Ä–∞–±–æ—Ç–∫–∞, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞

### **2. –†–∞–∑–º–µ—Ä –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:**
- **–ü—Ä–æ–±–ª–µ–º–∞**: torch + transformers = 2-3GB –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- **–†–µ—à–µ–Ω–∏–µ**: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –ª–µ–≥–∫–∏–µ –º–æ–¥–µ–ª–∏, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è

### **3. –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ—Å—Ç—å:**
- **–ü—Ä–æ–±–ª–µ–º–∞**: –ö–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∂–µ
- **–†–µ—à–µ–Ω–∏–µ**: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, fallback –Ω–∞ keyword –ø–æ–∏—Å–∫

### **4. –¢–æ—á–Ω–æ—Å—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞:**
- **–ü—Ä–æ–±–ª–µ–º–∞**: AI –º–æ–∂–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –ª–æ–∂–Ω—ã–µ —Å–≤—è–∑–∏
- **–†–µ—à–µ–Ω–∏–µ**: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ –ø–æ—Ä–æ–≥–∏, –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

---

## üéØ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –§–∞–∑—ã 2

### **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- ‚úÖ `find_similar_notes` —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é >80%
- ‚úÖ `search_contextual` –ø–æ–Ω–∏–º–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç  
- ‚úÖ `analyze_note_connections` –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏
- ‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫–∞–º
- ‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

### **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- üîÑ –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (—Ä—É—Å—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
- üîÑ GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–º–µ—Ç–æ–∫
- üîÑ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º explore_notes

---

## üí∞ –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤

### **–í—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã:**
- **–≠—Ç–∞–ø 2.1** (–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞): 1 –Ω–µ–¥–µ–ª—è (40 —á–∞—Å–æ–≤)
- **–≠—Ç–∞–ø 2.2** (–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫): 1-2 –Ω–µ–¥–µ–ª–∏ (40-80 —á–∞—Å–æ–≤)  
- **–≠—Ç–∞–ø 2.3** (–ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π): 1 –Ω–µ–¥–µ–ª—è (40 —á–∞—Å–æ–≤)
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: 1 –Ω–µ–¥–µ–ª—è (40 —á–∞—Å–æ–≤)

**–û–±—â–µ–µ –≤—Ä–µ–º—è: 4-5 –Ω–µ–¥–µ–ª—å (160-200 —á–∞—Å–æ–≤)**

### **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- **RAM**: 2-4GB –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
- **–î–∏—Å–∫**: 3-5GB –¥–ª—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π + –º–æ–¥–µ–ª–∏  
- **CPU**: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 4+ —è–¥–µ—Ä –¥–ª—è —Ä–∞–∑—É–º–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- **GPU**: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —É—Å–∫–æ—Ä–∏—Ç —Ä–∞–±–æ—Ç—É –≤ 5-10 —Ä–∞–∑

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ –§–∞–∑—ã 2

### **–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**
1. **–°–æ–∑–¥–∞—Ç—å –≤–µ—Ç–∫—É**: `git checkout -b phase-2-semantic-analysis`
2. **–û–±–Ω–æ–≤–∏—Ç—å pyproject.toml** —Å ML –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
3. **–°–æ–∑–¥–∞—Ç—å ai/ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é** –∏ –±–∞–∑–æ–≤—ã–µ –º–æ–¥—É–ª–∏
4. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ä–µ–¥—É** —Å –º–∞–ª—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
5. **–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å models.py** –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è embeddings

### **–ü–µ—Ä–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è (MVP):**
- –ë–∞–∑–æ–≤—ã–π `find_similar_notes` —Å all-MiniLM-L6-v2
- SQLite —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è embeddings  
- –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –Ω–∞ 10-20 –∑–∞–º–µ—Ç–∫–∞—Ö
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º obsidian-ai-mcp —Å–µ—Ä–≤–µ—Ä–æ–º

–ì–æ—Ç–æ–≤—ã –Ω–∞—á–∞—Ç—å –§–∞–∑—É 2? üöÄ
