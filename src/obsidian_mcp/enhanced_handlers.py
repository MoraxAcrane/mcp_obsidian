#!/usr/bin/env python3
"""
Enhanced handlers –¥–ª—è MCP —Å–µ—Ä–≤–µ—Ä–∞ Obsidian
–°–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≤—Å–µ—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

from mcp.types import TextContent, CallToolResult

from .utils.markdown_parser import (
    extract_outlinks,
    read_note_frontmatter, 
    write_note_frontmatter,
)
from .utils.vault import list_note_paths, note_path_for_title


def get_note_metadata(path: Path, content: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∑–∞–º–µ—Ç–∫–∏"""
    try:
        stat = path.stat()
        
        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        word_count = len(content.split())
        char_count = len(content)
        line_count = len(content.splitlines())
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫
        outlinks = extract_outlinks(content)
        link_count = len(outlinks)
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        tag_pattern = re.compile(r'#(\w+)')
        content_tags = list(set(tag_pattern.findall(content)))
        
        # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        heading_pattern = re.compile(r'^(#{1,6})\s+(.+)$', re.MULTILINE)
        headings = [{"level": len(match.group(1)), "text": match.group(2).strip()} 
                   for match in heading_pattern.finditer(content)]
        
        return {
            "file_info": {
                "size_bytes": stat.st_size,
                "created": datetime.fromtimestamp(stat.st_ctime).isoformat(),
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "accessed": datetime.fromtimestamp(stat.st_atime).isoformat()
            },
            "content_stats": {
                "word_count": word_count,
                "char_count": char_count,
                "line_count": line_count,
                "link_count": link_count,
                "heading_count": len(headings),
                "tag_count": len(content_tags)
            },
            "structure": {
                "headings": headings[:10],  # –ü–µ—Ä–≤—ã–µ 10 –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                "tags_in_content": content_tags,
                "outlinks": outlinks
            }
        }
    except Exception as e:
        return {"error": str(e)}


def analyze_vault_health(vault_path: Path) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –∑–¥–æ—Ä–æ–≤—å—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ vault"""
    try:
        all_notes = list(list_note_paths(vault_path))
        total_notes = len(all_notes)
        
        if total_notes == 0:
            return {"total_notes": 0, "message": "Vault is empty"}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        total_size = sum(path.stat().st_size for path in all_notes if path.exists())
        
        # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π
        all_links = []
        orphaned_notes = []
        notes_with_links = 0
        
        for note_path in all_notes:
            try:
                content, _ = read_note_frontmatter(note_path)
                outlinks = extract_outlinks(content)
                
                if outlinks:
                    all_links.extend(outlinks)
                    notes_with_links += 1
                else:
                    orphaned_notes.append(note_path.stem)
            except:
                continue
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫
        folders = set()
        for note_path in all_notes:
            if note_path.parent != vault_path:
                rel_folder = note_path.parent.relative_to(vault_path)
                folders.add(str(rel_folder))
        
        return {
            "overview": {
                "total_notes": total_notes,
                "total_size_mb": round(total_size / 1024 / 1024, 2),
                "folders_count": len(folders),
                "notes_with_links": notes_with_links,
                "orphaned_notes_count": len(orphaned_notes)
            },
            "health_metrics": {
                "connectivity_ratio": round(notes_with_links / total_notes * 100, 1),
                "average_links_per_note": round(len(all_links) / total_notes, 2),
                "folder_organization": "good" if len(folders) > 0 else "needs_folders"
            },
            "top_folders": list(folders)[:10],
            "orphaned_notes": orphaned_notes[:20],  # –ü–µ—Ä–≤—ã–µ 20
            "most_linked": list(set(all_links))[:10]  # –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å—Å—ã–ª–∫–∏
        }
        
    except Exception as e:
        return {"error": str(e)}


# =============================================================================
# –†–ê–°–®–ò–†–ï–ù–ù–´–ï –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò
# =============================================================================

async def handle_vault_overview(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üè† –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ vault —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"""
    include_detailed_stats = args.get("include_detailed_stats", True)
    
    vault_stats = analyze_vault_health(vault_path)
    
    if include_detailed_stats and "health_metrics" in vault_stats:
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        recommendations = []
        
        connectivity = vault_stats["health_metrics"]["connectivity_ratio"]
        if connectivity < 20:
            recommendations.append("üîó Low connectivity - consider linking related notes")
        elif connectivity > 80:
            recommendations.append("‚úÖ Excellent connectivity - well-connected knowledge base")
        
        if vault_stats["overview"]["orphaned_notes_count"] > 5:
            recommendations.append("üèùÔ∏è Many orphaned notes - consider creating connections")
        
        if vault_stats["overview"]["folders_count"] == 0:
            recommendations.append("üìÅ No folder structure - consider organizing notes into folders")
        
        vault_stats["recommendations"] = recommendations
    
    result = {
        "tool": "vault_overview",
        "timestamp": datetime.now().isoformat(),
        "vault_analysis": vault_stats
    }
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_read_note_enhanced(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üìñ –ß—Ç–µ–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
    title = args["title"]
    include_backlinks = args.get("include_backlinks", True)
    include_outlinks = args.get("include_outlinks", True)
    include_metadata = args.get("include_metadata", True)
    
    path = note_path_for_title(vault_path, title)
    if not path.exists():
        return CallToolResult(content=[TextContent(type="text", text=f"‚ùå Note not found: {title}")])
    
    content, frontmatter_metadata = read_note_frontmatter(path)
    
    result = {
        "tool": "read_note_enhanced",
        "title": title,
        "content": content,
        "frontmatter": frontmatter_metadata
    }
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    if include_metadata:
        result["enhanced_metadata"] = get_note_metadata(path, content)
    
    # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π
    if include_outlinks:
        result["outlinks"] = extract_outlinks(content)
        
    if include_backlinks:
        backlinks = []
        needle = f"[[{title}]]"
        for other in list_note_paths(vault_path):
            if other == path:
                continue
            try:
                text = other.read_text(encoding="utf-8")
                if needle in text:
                    backlinks.append(other.stem)
            except Exception:
                continue
        result["backlinks"] = backlinks
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_note_exists(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∑–∞–º–µ—Ç–∫–∏ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏"""
    title = args["title"]
    return_suggestions = args.get("return_suggestions", True)
    
    path = note_path_for_title(vault_path, title)
    exists = path.exists()
    
    result = {
        "tool": "note_exists",
        "title": title,
        "exists": exists
    }
    
    if exists:
        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        try:
            stat = path.stat()
            result["basic_info"] = {
                "path": str(path.relative_to(vault_path)),
                "size_bytes": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat()
            }
        except Exception as e:
            result["info_error"] = str(e)
    
    elif return_suggestions:
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–º–µ—Ç–∫–∏ –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        similar_notes = []
        title_lower = title.lower()
        
        for note_path in list_note_paths(vault_path):
            note_title = note_path.stem.lower()
            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ
            if title_lower in note_title or note_title in title_lower:
                similar_notes.append(note_path.stem)
        
        result["suggestions"] = similar_notes[:5]  # –¢–æ–ø 5 –ø–æ—Ö–æ–∂–∏—Ö
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_create_note_smart(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """‚ú® –£–º–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏"""
    title = args["title"]
    content = args["content"]
    tags = args.get("tags", [])
    folder = args.get("folder")
    auto_enhance = args.get("auto_enhance", True)
    suggest_connections = args.get("suggest_connections", True)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
    path = note_path_for_title(vault_path, title, folder)
    if path.exists():
        return CallToolResult(content=[TextContent(type="text", text=f"‚ùå Note already exists: {title}")])
    
    result = {
        "tool": "create_note_smart",
        "title": title,
        "path": str(path)
    }
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
    if auto_enhance:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_tags = re.findall(r'#(\w+)', content)
        suggested_tags = list(set(tags + content_tags))
        
        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–∞–ø–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–≥–æ–≤ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        if not folder:
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–∞–ø–æ–∫
            content_lower = content.lower()
            if any(word in content_lower for word in ['programming', 'code', 'python', 'javascript']):
                result["suggested_folder"] = "Programming"
            elif any(word in content_lower for word in ['project', 'task', 'work']):
                result["suggested_folder"] = "Projects"  
            elif any(word in content_lower for word in ['learn', 'study', 'course']):
                result["suggested_folder"] = "Learning"
        
        result["auto_tags"] = suggested_tags
        tags = suggested_tags  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏
    metadata = {}
    if tags:
        metadata["tags"] = tags
    if auto_enhance:
        metadata["created_with"] = "enhanced_mcp_server"
        metadata["created_date"] = datetime.now().isoformat()
    
    write_note_frontmatter(path, content, metadata)
    result["created"] = True
    
    # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–≤—è–∑–µ–π
    if suggest_connections:
        potential_connections = []
        content_words = set(content.lower().split())
        
        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–º–µ—Ç–∫–∏ —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
        for note_path in list_note_paths(vault_path):
            if note_path == path:
                continue
                
            note_title_words = set(note_path.stem.lower().split())
            # –ü—Ä–æ—Å—Ç–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤
            common_words = content_words.intersection(note_title_words)
            if len(common_words) > 0:
                potential_connections.append({
                    "note": note_path.stem,
                    "reason": f"Common words: {', '.join(list(common_words)[:3])}"
                })
        
        result["suggested_connections"] = potential_connections[:5]
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_append_to_note(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üìù –£–º–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫ –∑–∞–º–µ—Ç–∫–µ"""
    title = args["title"]
    content = args["content"]
    section = args.get("section")
    format_style = args.get("format_style", "append")
    add_timestamp = args.get("add_timestamp", False)
    
    path = note_path_for_title(vault_path, title)
    if not path.exists():
        return CallToolResult(content=[TextContent(type="text", text=f"‚ùå Note not found: {title}")])
    
    current_content, metadata = read_note_frontmatter(path)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–±–∞–≤–ª—è–µ–º–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    addition = content
    
    if add_timestamp:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        addition = f"*{timestamp}*: {addition}"
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∏–ª—è
    if format_style == "bullet":
        addition = f"- {addition}"
    elif format_style == "heading":
        addition = f"## {addition}"
    elif format_style == "paragraph":
        addition = f"\n{addition}\n"
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–µ–∫—Ü–∏–∏ –∏–ª–∏ –≤ –∫–æ–Ω–µ—Ü
    if section:
        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–µ—ë
        section_pattern = rf"(^#+\s+{re.escape(section)}.*?$)"
        if re.search(section_pattern, current_content, re.MULTILINE):
            # –°–µ–∫—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ –Ω–µ—ë
            new_content = re.sub(
                section_pattern + r"(\n.*?)(?=^#+|\Z)",
                rf"\1\2\n{addition}",
                current_content,
                flags=re.MULTILINE | re.DOTALL
            )
        else:
            # –°–µ–∫—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            new_content = current_content.rstrip() + f"\n\n## {section}\n{addition}"
    else:
        # –ü—Ä–æ—Å—Ç–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü
        separator = "\n\n" if not current_content.endswith("\n") else "\n"
        new_content = current_content + separator + addition
    
    write_note_frontmatter(path, new_content, metadata)
    
    result = {
        "tool": "append_to_note",
        "title": title,
        "appended": True,
        "format_used": format_style,
        "section_used": section if section else "end_of_note",
        "addition_preview": addition[:100] + "..." if len(addition) > 100 else addition
    }
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_create_folder(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫"""
    folder_path = args["folder_path"]
    create_index = args.get("create_index", True)
    index_template = args.get("index_template", "basic")
    
    full_path = vault_path / folder_path
    full_path.mkdir(parents=True, exist_ok=True)
    
    result = {
        "tool": "create_folder", 
        "folder_path": folder_path,
        "created": True,
        "full_path": str(full_path)
    }
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–Ω–æ–π –∑–∞–º–µ—Ç–∫–∏
    if create_index:
        index_name = f"{folder_path.split('/')[-1]} - Index"
        index_path = full_path / f"{index_name}.md"
        
        # –®–∞–±–ª–æ–Ω—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–Ω–æ–π –∑–∞–º–µ—Ç–∫–∏
        templates = {
            "basic": f"# {folder_path.split('/')[-1]}\n\n## Overview\n\nThis folder contains notes about {folder_path.split('/')[-1].lower()}.\n\n## Notes\n\n",
            "moc": f"# {folder_path.split('/')[-1]} - MOC (Map of Content)\n\n## Core Concepts\n\n## Related Notes\n\n## Resources\n\n",
            "structured": f"# {folder_path.split('/')[-1]}\n\n## üìã Overview\n\n## üìù Notes\n\n## üîó Related Topics\n\n## üìö Resources\n\n## üè∑Ô∏è Tags\n\n"
        }
        
        index_content = templates.get(index_template, templates["basic"])
        index_path.write_text(index_content, encoding="utf-8")
        
        result["index_created"] = {
            "name": index_name,
            "template": index_template,
            "path": str(index_path.relative_to(vault_path))
        }
    
    return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])


async def handle_explore_notes(vault_path: Path, args: Dict[str, Any]) -> CallToolResult:
    """üîç –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –∑–∞–º–µ—Ç–æ–∫ —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π –∏ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
    from .smart_search import SmartSearchEngine
    
    keywords = args["keywords"]
    search_in = args.get("search_in", "all")
    language_flexible = args.get("language_flexible", True)
    case_sensitive = args.get("case_sensitive", False) 
    limit = min(args.get("limit", 15), 30)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ 30
    include_content_preview = args.get("include_content_preview", True)
    min_relevance = args.get("min_relevance", 0.1)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –¥–≤–∏–∂–æ–∫
        search_engine = SmartSearchEngine(vault_path)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        search_result = search_engine.search_notes(
            keywords=keywords,
            search_in=search_in,
            language_flexible=language_flexible,
            case_sensitive=case_sensitive,
            limit=limit,
            include_content_preview=include_content_preview,
            min_relevance=min_relevance
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–∏—Å–∫–µ
        result = {
            "tool": "explore_notes",
            "timestamp": datetime.now().isoformat(),
            "search_performed": True,
            **search_result
        }
        
        return CallToolResult(content=[TextContent(type="text", text=json.dumps(result, ensure_ascii=False, indent=2))])
        
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"Error in explore_notes: {e}")
        
        error_result = {
            "tool": "explore_notes",
            "error": str(e),
            "search_query": keywords,
            "results": [],
            "total_found": 0,
            "fallback_suggestion": "Try using list_notes or simplify your search keywords"
        }
        
        return CallToolResult(content=[TextContent(type="text", text=json.dumps(error_result, ensure_ascii=False, indent=2))])
